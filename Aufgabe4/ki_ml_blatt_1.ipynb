{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PohCF88YwWgk"
   },
   "source": [
    "# Aufgaben Blatt 4 KI Machine Learning I\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9sieFkrwWgm"
   },
   "source": [
    "## Aufgabe 1 (Lineare Regression)\n",
    "\n",
    "Bearbeiten Sie die Aufgabe https://github.com/oduerr/ki/blob/main/linear_regression/lr_gradient_descent.ipynb\n",
    "\n",
    "Versuchen Sie den Code zu verstehen und machen die kleineren Aufgaben, die in dem notebook besprochen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr2BSdsNwWgm"
   },
   "source": [
    "## Aufgabe 2 (Titanic)\n",
    "In dieser Aufgabe nehmen Sie an der Titanic Challenge (https://www.kaggle.com/c/titanic) teil. Sie können die Aufgabe am eigenen PC lösen oder direkt in Kaggle lösen. Die Daten liegen auch auf Moodle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-_0tiX-wWgm"
   },
   "source": [
    "a) Lesen Sie die Trainingsdaten ein und teilen Sie sie in ein Validierungsdatenset (20%) und in ein eigentliches Trainigsdatenset (80%) auf. Finden Sie auf dem Validierungsdatensatz eine Regel für das Überleben alleine aufgrund der Klasse des Tickets (Pclass). Wenden Sie diese Regel auf die Validierungsdaten an. Wie gut ist die Genauigkeit (Anteil der korrekten Klassifikationen) auf den Validierungsdaten?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PGm0-jEawWgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 80\n",
      "87 97\n",
      "119 372\n",
      "0.6296296296296297 0.47282608695652173 0.24236252545824846\n"
     ]
    }
   ],
   "source": [
    "# Hinweise zum Einlesen\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "train_val = pd.read_csv('train.csv')\n",
    "\n",
    "# Hinweise zum Erzeugen einer Tabelle\n",
    "# pd.crosstab(...)\n",
    "\n",
    "# Hinweise um die Accuracy zu berechnen\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "#print(train_val.loc[:,[\"Survived\", \"Pclass\"]])\n",
    "\n",
    "train, validation = train_test_split(train_val, test_size=0.2)\n",
    "\n",
    "c1_survived = len(train_val.loc[(train_val['Pclass'] == 1) & (train_val['Survived'] == 1)])\n",
    "c1_died = len(train_val.loc[(train_val['Pclass'] == 1) & (train_val['Survived'] == 0)])\n",
    "\n",
    "c2_survived = len(train_val.loc[(train_val['Pclass'] == 2) & (train_val['Survived'] == 1)])\n",
    "c2_died = len(train_val.loc[(train_val['Pclass'] == 2) & (train_val['Survived'] == 0)])\n",
    "\n",
    "c3_survived = len(train_val.loc[(train_val['Pclass'] == 3) & (train_val['Survived'] == 1)])\n",
    "c3_died = len(train_val.loc[(train_val['Pclass'] == 3) & (train_val['Survived'] == 0)])\n",
    "\n",
    "print(c1_survived, c1_died)\n",
    "print(c2_survived, c2_died)\n",
    "print(c3_survived, c3_died)\n",
    "\n",
    "prob1 = c1_survived / (c1_survived + c1_died)\n",
    "prob2 = c2_survived / (c2_survived + c2_died)\n",
    "prob3 = c3_survived / (c3_survived + c3_died)\n",
    "\n",
    "print(prob1, prob2, prob3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAb6YDtTwWgn"
   },
   "source": [
    "b) Wenden Sie die Regel aus a) auf die Testdaten an und laden Sie Ihre Lösung hoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeplTB8SwWgo",
    "outputId": "98e2e1d5-0b85-4bb6-beb5-25e200b94913"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "test_data = pd.read_csv('test.csv')\n",
    "pred_survived = []#Enhält die Predictions 0 für Tod 1 für Survived\n",
    "train_val = pd.read_csv('train.csv')\n",
    "train, validation = train_test_split(train_val, test_size=0.2)\n",
    "\n",
    "#Aufgabe b)\n",
    "\"\"\"\n",
    "for i, row in test_data.iterrows():\n",
    "    q = row['Pclass']\n",
    "    if q == 1:\n",
    "        if random.random() < 0.6296296296296297:\n",
    "            pred_survived.append(1)\n",
    "        else:\n",
    "            pred_survived.append(0)\n",
    "    elif q == 2:\n",
    "        if random.random() < 0.47282608695652173:\n",
    "            pred_survived.append(1)\n",
    "        else:\n",
    "            pred_survived.append(0)\n",
    "    elif q == 3:\n",
    "        if random.random() < 0.24236252545824846:\n",
    "            pred_survived.append(1)\n",
    "        else:\n",
    "            pred_survived.append(0)\n",
    "\"\"\"\n",
    "\n",
    "#Aufgabe c)\n",
    "from sklearn.linear_model import LogisticRegression #aufgabe c\n",
    "import numpy as np\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "\"\"\"\n",
    "#x = class\n",
    "#y = died or survived\n",
    "x = train_val['Pclass'].tolist()\n",
    "y = train_val['Survived'].tolist()\n",
    "\n",
    "train_x = np.array(x).reshape(len(x), 1)\n",
    "train_y = np.array(y)\n",
    "\n",
    "logisticRegr.fit(train_x, train_y)\n",
    "\n",
    "test_list = test_data['Pclass'].tolist()\n",
    "test_data_prediction = np.array(test_list).reshape(len(test_list), 1)\n",
    "\n",
    "#pred_survived = logisticRegr.predict(test_data_prediction)\n",
    "\"\"\"\n",
    "\n",
    "# Hinweise zum rausschreiben\n",
    "\n",
    "#Aufgabe d)\n",
    "\"\"\"\n",
    "train_val['Age'].fillna(train[\"Age\"].median(skipna=True), inplace=True)\n",
    "x = train_val['Age'].tolist()\n",
    "y = train_val['Survived'].tolist()\n",
    "\n",
    "train_x = np.array(x).reshape(len(x), 1)\n",
    "train_y = np.array(y)\n",
    "\n",
    "logisticRegr.fit(train_x, train_y)\n",
    "\n",
    "test_data['Age'].fillna(train[\"Age\"].median(skipna=True), inplace=True)\n",
    "test_list = test_data['Age'].tolist()\n",
    "test_data_prediction = np.array(test_list).reshape(len(test_list), 1)\n",
    "\n",
    "pred_survived = logisticRegr.predict(test_data_prediction)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#Aufgabe d.2)\n",
    "train['Age'].fillna(train[\"Age\"].median(skipna=True), inplace=True)\n",
    "test_data['Age'].fillna(train[\"Age\"].median(skipna=True), inplace=True)\n",
    "\n",
    "sex = pd.get_dummies(train[\"Sex\"], drop_first=True)\n",
    "pclass = pd.get_dummies(train[\"Pclass\"], drop_first=True)\n",
    "\n",
    "train_y = np.array(train['Survived'].tolist())\n",
    "\n",
    "train_x = pd.concat([sex, pclass, train[\"Age\"]], axis=1)\n",
    "\n",
    "logisticRegr.fit(train_x, train_y)\n",
    "\n",
    "print(train_x)\n",
    "\n",
    "test_sex = pd.get_dummies(test_data[\"Sex\"], drop_first=True)\n",
    "test_pclass = pd.get_dummies(test_data[\"Pclass\"], drop_first=True)\n",
    "\n",
    "test_x = pd.concat([test_sex, test_pclass, test_data[\"Age\"]], axis=1)\n",
    "\n",
    "print(test_x)\n",
    "\n",
    "pred_survived = logisticRegr.predict(test_x)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#Aufgabe e)\n",
    "# Hinweise zur Lösung\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "#rf hat nun gleiches interface, wie die logistische Regression\n",
    "\n",
    "train['Age'].fillna(train[\"Age\"].median(skipna=True), inplace=True)\n",
    "test_data['Age'].fillna(train[\"Age\"].median(skipna=True), inplace=True)\n",
    "\n",
    "sex = pd.get_dummies(train[\"Sex\"], drop_first=True)\n",
    "pclass = pd.get_dummies(train[\"Pclass\"], drop_first=True)\n",
    "\n",
    "train_y = np.array(train['Survived'].tolist())\n",
    "\n",
    "train_x = pd.concat([sex, pclass, train[\"Age\"]], axis=1)\n",
    "\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "#print(train_x)\n",
    "\n",
    "test_sex = pd.get_dummies(test_data[\"Sex\"], drop_first=True)\n",
    "test_pclass = pd.get_dummies(test_data[\"Pclass\"], drop_first=True)\n",
    "\n",
    "test_x = pd.concat([test_sex, test_pclass, test_data[\"Age\"]], axis=1)\n",
    "\n",
    "#print(test_x)\n",
    "\n",
    "pred_survived = rf.predict(test_x)\n",
    "\n",
    "\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': pred_survived})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0YqDhK3wWgp"
   },
   "source": [
    "c) Logistische Regression mit Pclass\n",
    "\n",
    "Trainieren Sie eine logistische Regression mit den Variablen 'Pclass'. Verwenden Sie die Klasse `sklearn.linear_model.LogisticRegression`. Berechnen Sie die Accuracy auf dem Validierungsset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-xC04XswWgp"
   },
   "source": [
    "d) Coding / Feature engineering \n",
    "\n",
    "d.i) Missing Values:\n",
    "\n",
    "Verwenden Sie nun weitere Features. Die Variable Age enthält Missing values, die Sie durch folgenden code ersetzen können (was passiert da?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6i9qi9ywwWgq"
   },
   "outputs": [],
   "source": [
    "val[\"Age\"].fillna(train[\"Age\"].median(skipna=True), inplace=True)\n",
    "train[\"Age\"].fillna(train[\"Age\"].median(skipna=True), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxNwZco7wWgq"
   },
   "source": [
    "d.ii) Kategorische Variable\n",
    "\n",
    "Verwenden Sie die Funktion `pd.get_dummies` um die Variablen 'Pclass' and 'Sex' in numerische Werte umzuwandeln. Führen Sie nun eine logistische Regression durch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yu8UOcKAwWgq"
   },
   "source": [
    "e) Weitere Klassifikatoren. Neben der logistischen Regression, gibt es weitere Klassifikatoren. Der Random-Forest ist ein recht stabiler Klassifikator, was wäre die Performance von diesem Klassifikator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0eRJVGSwWgr"
   },
   "outputs": [],
   "source": [
    "# Hinweise zur Lösung\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "#rf hat nun gleiches interface, wie die logistische Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oe_oIy11wWgr"
   },
   "source": [
    "f) [optional] Versuchen Sie weitere Features zu erzeugen und laden den besten Klassifikator auf Kaggle hoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc49pWuewWgr"
   },
   "source": [
    "## Aufgabe 3 Titanic mit Neuronalen Netzen \n",
    "\n",
    "Hinweis: Diese Aufgabe kann erst nach der dritten Vorlesung in ML gemacht werden.\n",
    "\n",
    "Mit den gleichen Daten, wie in der Aufgabe 2 d. Erstellen Sie ein fully connected neural network und fitten es an die Ttrainingsdaten. Verwenden Sie mindestens zwei hidden Layer. Plotten Sie den Verlauf der Loss Kurve für die Trainings- und Validierungsdaten. Optional: Laden Sie Ihre beste Lösung auf Kaggle hoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aYxfamTkwWgr",
    "outputId": "80a28e11-8256-4ab2-97ad-8f1d0ddda78e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install tensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Sie können von folgendem Code starten um das Netzwerk zu definieren, füllen Sie die ...\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Sie können von folgendem Code starten um das Netzwerk zu definieren, füllen Sie die ...\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Define Network\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='sigmoid', batch_input_shape=(None, 3))) #We have 3 input features\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compile Network\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Fit Network\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_val = pd.read_csv('train.csv')\n",
    "\n",
    "train_val['Age'].fillna(train_val[\"Age\"].median(skipna=True), inplace=True)\n",
    "test_data['Age'].fillna(train_val[\"Age\"].median(skipna=True), inplace=True)\n",
    "\n",
    "train, valid = train_test_split(train_val, test_size=0.2)\n",
    "\n",
    "#train\n",
    "sex = pd.get_dummies(train[\"Sex\"], drop_first=True)\n",
    "pclass = train[\"Pclass\"]\n",
    "age = train[\"Age\"]\n",
    "train_y = np.array(train['Survived'].tolist())\n",
    "train_x = pd.concat([sex, pclass, age], axis=1)\n",
    "\n",
    "#valid\n",
    "sex_v = pd.get_dummies(valid[\"Sex\"], drop_first=True)\n",
    "pclass_v = valid[\"Pclass\"]\n",
    "age_v = valid[\"Age\"]\n",
    "valid_y = np.array(valid['Survived'].tolist())\n",
    "valid_x = pd.concat([sex_v, pclass_v, age_v], axis=1)\n",
    "\n",
    "history = model.fit(np.asarray(train_x).astype('float32'), np.asarray(train_y).astype('float32'), batch_size=128, epochs=150, verbose=2, validation_data=(np.asarray(valid_x).astype('float32'), np.asarray(valid_y).astype('float32')))\n",
    "\n",
    "#Make Predictions\n",
    "sex_p = pd.get_dummies(test_data[\"Sex\"], drop_first=True)\n",
    "pclass_p = test_data[\"Pclass\"]\n",
    "age_p = test_data[\"Age\"]\n",
    "prediction_data = pd.concat([sex_p, pclass_p, age_p], axis=1)\n",
    "pred_survived = model.predict(np.asarray(prediction_data).astype('float32'))\n",
    "\n",
    "pred_survived = np.round(pred_survived, 0).astype(int)\n",
    "\n",
    "#Summary\n",
    "model.summary()\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': pred_survived.flatten()})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9M8BQdo5wWgs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ki_ml_blatt_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
